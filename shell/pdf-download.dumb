#!/bin/bash

#URL = http://someURL/docs/         # website which have the PDFs, ofc
#seq -f "0-HC%.0f-0" 1 1 50 |       # navigating though the diffrent URL paths
#  xargs -n 1 -P 8 -I@ {{ [         # prossess/download 8 files at a time
#    $(curl -s -L -I http://alsaedy.online/v/@ |         #get file info
#    gawk -v IGNORECASE=1 '/^Content-Length/ { print $2 }') -gt 20480 #compare size
#  ] && wget $URL@; } || wget -L -O @.pdf -P ~/SavedPDFs/ $URL@} # if ok, save! 

#seq -f "0-HC%.0f-0" 1 1 50 | \
#  xargs -n 1 -P 8 -I@ echo



download() {
  echo "do stuff for $1"
}
export -f download

seq -f "0-HC%.0f-0" 1 1 50 | \
  xargs -n 1 -P 8 -I@ bash -c 'download @'
